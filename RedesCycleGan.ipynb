{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedesCycleGan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uriel825/Experimentos-Pytorch/blob/master/RedesCycleGan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPmj8s_aQRXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_L42Ux_Qio7",
        "colab_type": "code",
        "outputId": "ce7fbaaf-b11a-4fc5-a27a-7a76aa3bd3dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd '/gdrive/My Drive'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQNB5UtaRyFH",
        "colab_type": "code",
        "outputId": "10404477-f158-45b0-8aec-e2a90e92950a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!git clone https://github.com/aitorzip/PyTorch-CycleGAN.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'PyTorch-CycleGAN' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VdK9vgfSSn4",
        "colab_type": "code",
        "outputId": "786333b4-b1af-43a6-c55c-8e45f0d46908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%cd '/gdrive/My Drive/PyTorch-CycleGAN'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/PyTorch-CycleGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHy16fbYSoLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%sh\n",
        "#sh ./download_dataset summer2winter_yosemite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INGThZgXS32P",
        "colab_type": "code",
        "outputId": "242f63f4-9129-4726-b6ee-b506f9ca918f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!mv datasets/summer2winter_yosemite /gdrive/My\\ Drive/dl-pytorch/datasets/\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat 'datasets/summer2winter_yosemite': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEuwz6kdTM_J",
        "colab_type": "code",
        "outputId": "c4acd964-2cc1-4519-b54d-2fb018736d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "!ls /gdrive/My\\ Drive/dl-pytorch/datasets/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64x64_SIGNS\t cifar-10-batches-py\t summer2winter_yosemite\n",
            "64x64_SIGNS.zip  cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUMemwEaUszD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHttitC3Xqbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_features):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    conv_block = [ nn.ReflectionPad2d(1), #rellena la red\n",
        "                 nn.Conv2d(in_features, in_features, 3),\n",
        "                 nn.InstanceNormd2d(in_features), #BN para gans\n",
        "                 nn.ReLU(True),\n",
        "                 nn.ReflectionPad2d(1), #mejor para mantener la distribucion\n",
        "                 nn.Conv2d(in_features, in_features, 3),\n",
        "                 nn.InstanceNormd2d(in_features)\n",
        "                ]  \n",
        "    self.conv_block = nn.Sequential(*conv_block)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return self.conv_block(x) + x #Juega con el espacio de modelos \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9vehhp0XsRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, input_nc, output_nc, n_residuals_blocks=9):\n",
        "    super(Generator,self).__init__()\n",
        "    \n",
        "    #Bloque convulusional\n",
        "    model = [ nn.ReflectionPad2d(3),\n",
        "              nn.Conv2d(input_nc, 64, F), #I-7+6/1 +1 = I\n",
        "              nn.InstanceNorm2d (64),\n",
        "              nn.ReLU(True)\n",
        "            ]\n",
        "    in_features = 64\n",
        "    out_features = in_features * 2\n",
        "     \n",
        "    #Capa de enconding\n",
        "    for _ in range(2):\n",
        "      model += [ nn.Conv2d(in_features, out_features, 3, stride=2, padding=1), #I/2 \n",
        "                 nn.InstanceNorm2d(out_features),\n",
        "                 nn.ReLU(True)\n",
        "               ]\n",
        "      in_features = out_features\n",
        "      out_features = in_features*2\n",
        "    #Tranformasiones residuales\n",
        "\n",
        "    for _ in range(n_residuals_blocks):\n",
        "      model += [ResidualBlock(in_features)]\n",
        "    \n",
        "    #Capa de decoding\n",
        "    out_features = in_features//2\n",
        "    for _ in range(2):\n",
        "      model += [nn.ConvTranspose2d(in_features, out_features, 3, stride=2, padding=1, output_padding=1),#I*2\n",
        "                nn.InstanceNorm2d(out_features),\n",
        "                nn.ReLU(True)\n",
        "               ]\n",
        "      in_features = out_features\n",
        "      out_features = in_features //2\n",
        "\n",
        "      #salida\n",
        "      model += [ nn.ReflectionPad2d(3),\n",
        "                 nn.Conv2d(64, output_nc, 7),#I\n",
        "                 nn.Tanh()\n",
        "              ] \n",
        "\n",
        "      self.model = nn.Sequential(*model)\n",
        "\n",
        "      #Metodo Fordward\n",
        "      def fordward(self,x):\n",
        "        return self.model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSC03_7C6Tee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Red Discriminativa\n",
        "\n",
        "class Discrimanator(nn.Module):\n",
        "  \"patchGAN: Discrimina estilo o Textura\"\n",
        "  def __init__(self, input_nc):\n",
        "    super(Discrimanator, self).__init__()\n",
        "\n",
        "    model = [ nn.Conv2d(input_nc, 64, 4, stride=2, padding=1), #I/2\n",
        "              nn.LeakyReLU(0.2, in_place=True)\n",
        "            ]\n",
        "    \n",
        "    model += [ nn.Conv2d(64, 128, 4, stride=2, padding=1), #I/2\n",
        "               nn.InstanceNorm2d(128),\n",
        "               nn.LeakyReLU(0.2, in_place=True)\n",
        "             ]\n",
        "    model += [ nn.Conv2d(128, 256, 4, stride=2, padding=1), #I/2\n",
        "               nn.InstanceNorm2d(256),\n",
        "               nn.LeakyReLU(0.2, in_place=True)\n",
        "             ]\n",
        "    \n",
        "    model += [ nn.Conv2d(256, 512, 4, padding=1), #I/2\n",
        "               nn.InstanceNorm2d(256),\n",
        "               nn.LeakyReLU(0.2, in_place=True)\n",
        "             ]\n",
        "    \n",
        "    #Flatten\n",
        "    model += [nn.Conv2d(512, 1, 4, padding=1)] #I-1\n",
        "\n",
        "    self.model == nn.Sequential(*model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.model(x)\n",
        "    return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvsytvQjEtPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Entrenamiento\n",
        "import sys\n",
        "import argparse\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "sys.path.append('/gdrive/My Drive/dl-pytorch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kNeg7c0iLjgL",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FdBSp7qFSgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, base_dir, transform=None, split='train'):\n",
        "    self.tramsform = transforms.Compose(transform) #Hack pemite quitar el if x asocia a x\n",
        "    self.file_A = sorted(glob.glob(os.path.join(base_dir,'{}/A/*.*'.format(split)))) #se usa para ir al base dir de A va a ir a buscar las imagenes con extensiones \n",
        "    self.file_B = sorted(glob.glob(os.path.join(base_dir,'{}/B/*.*'.format(split)))) #sorted = ordenado\n",
        "  def __len__ (self):\n",
        "    return max(len(self.files_a), len(self.files_B))\n",
        "  def __getitem__(self,idx): #idx = index\n",
        "    image_A = self.transform(Image.open(self.files_A[idx]))\n",
        "    image_B = self.transform(Image.open(self.files_A[random.randint(0,len(self.files_B)-1)]))\n",
        "    return {'A':image_A, 'B':image_B}\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ruhw0T-7kuB",
        "colab_type": "text"
      },
      "source": [
        "  Instanciando todo lo necesario\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I96rM6WG7nc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epoch = 0\n",
        "n_epochs = 200\n",
        "batch_size = 4 #Es bueno entrenar con smalls batchs\n",
        "lr = 1e-3\n",
        "size = 256\n",
        "input_nc = 3\n",
        "output_nc = 3\n",
        "decay_epoch = 100 #pending\n",
        "\n",
        "cuda=True\n",
        "n_cpu = 8 #Paralizar los datos\n",
        "\n",
        "base_dir = '/gdrive/My Drive/dl-pytorch/datasets/summer2winter_yosemite'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYact3L_8FBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if cuda else 'cpu')\n",
        "def weights_init_normal(m):\n",
        "  classname = m.__class.__name__\n",
        "  if classname.find('Conv') !=1:\n",
        "      torch.nn.init.normal(m.weight.data, 0.0, 1e-2) #Inicializacion con distribucion gaussiana\n",
        "  elif classname.find('BatchNorm2d') !=1:\n",
        "      torch.nn.init.normal(m.weight.data, 1.0, 1e-2) #solo cambiar el 0 por 1\n",
        "      torch.nn.init.constant(m.bias, 0.0) #capa bias\n",
        "\n",
        "netG_A2B = Generator(input_nc, output_nc)\n",
        "netG_B2A = Generator(output_nc, input_nc)\n",
        "netD_A = Discriminator(input_nc)\n",
        "netD_B = Discriminator(output_nc)\n",
        "\n",
        "if cuda:\n",
        "      netG_A2B.to(device)\n",
        "      netG_B2A.to(device)\n",
        "      netD_A.to(device)\n",
        "      netD_B.to(device)\n",
        "\n",
        "netG_A2B.apply(weights_init_normal)\n",
        "netG_B2A.apply(weights_init_normal)\n",
        "netD_A.apply(weights_init_normal)\n",
        "netD_B.apply(weights_init_normal)\n",
        "\n",
        "# Lossess\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "halEe7PQLt9Z",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yq3lex7_1VQ",
        "colab_type": "text"
      },
      "source": [
        "Optmizadores y scheduales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47XqUI8_AWC1",
        "colab_type": "code",
        "outputId": "0d183aa9-1667-4f9d-ebcf-c6643fd66f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netGB2A.parameters()),#Juntar parametros y entrenar al mismo tiempo\n",
        "                               lr=lr, betas=(0.5, 0.999)) \n",
        "optmizer_D_A = torch.optim.Adam(netD_A().parameters, lr=lr, betas=(0.5, 0.999))\n",
        "optmizer_D_B = torch.optim.Adam(netD_B().parameters, lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "#schedualers (Permiten actualizar el Learning rate de manera dinamica durante el entrenamiento)\n",
        "class LambdaLR():\n",
        "    def __init__ (self, n_epochs, offset, decay_start_epoch): #El decaimiento del epcoh se hace cuando ya llava altos parametros de entrenamiento\n",
        "      assert((n_epochs-decay_start_epoch)>0)\n",
        "      self.n_epochs = n_epochs\n",
        "      self.offset = offset\n",
        "      self.decay_start_epoch = decay_start_epoch\n",
        "    def step(self, epoch):\n",
        "      return 1 - max(0,epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch) \n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step) #Permite crear un funcion lambda\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step)\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs,epoch,decay_epoch).step)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-cae8dfcf9ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netGB2A.parameters()),#Juntar parametros y entrenar al mismo tiempo\n\u001b[0m\u001b[1;32m      2\u001b[0m                                lr=lr, betas=(0.5, 0.999)) \n\u001b[1;32m      3\u001b[0m \u001b[0moptmizer_D_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetD_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptmizer_D_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetD_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'netG_A2B' is not defined"
          ]
        }
      ]
    }
  ]
}